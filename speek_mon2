import threading
import time
import collections
import pyaudio
import webrtcvad
import wave
import sounddevice as sd
import soundfile as sf
from funasr import AutoModel
import requests
import json
from queue import Queue

# ====== 全局变量 ======
RATE = 16000
CHANNELS = 1
FORMAT = pyaudio.paInt16
CHUNK_MS = 30
CHUNK_SIZE = int(RATE * CHUNK_MS / 1000)
VAD_MODE = 2
SILENCE_TIMEOUT = 3.0
OUTPUT_FILE = "recorded.wav"
flag_path = "/tmp/flag.txt"

interrupt_event = threading.Event()  # 全局中断事件
process_lock = threading.Lock()      # 保证单流程
tts_queue = Queue(maxsize=1)         # 队列长度=1,最新任务覆盖旧任务
player_queue = Queue(maxsize=1)
stt_model = AutoModel(model="/home/b/daniel/funasr-project/FunASR/models", disable_update=True)
conversation_id = None

# ====== 录音类 ======
class MicRecorder:
    def __init__(self):
        self.vad = webrtcvad.Vad(VAD_MODE)
        self.pa = pyaudio.PyAudio()
        self.stream = self.pa.open(format=FORMAT, channels=CHANNELS,
                                   rate=RATE, input=True, frames_per_buffer=CHUNK_SIZE)

    def is_speech(self, frame_bytes):
        return self.vad.is_speech(frame_bytes, RATE)

    def record_once(self):
        print("[*] 等待录音信号...")
        while not interrupt_event.is_set():
            time.sleep(0.05)

        print("[+] 录音开始...")
        frames = []
        silent_chunks = collections.deque(maxlen=int(SILENCE_TIMEOUT*1000/CHUNK_MS))

        while True:
            if interrupt_event.is_set() and frames:
                print("[!] 录音被打断")
                break
            frame = self.stream.read(CHUNK_SIZE, exception_on_overflow=False)
            if self.is_speech(frame):
                frames.append(frame)
                silent_chunks.clear()
            else:
                if frames:
                    silent_chunks.append(frame)
                    if len(silent_chunks) == silent_chunks.maxlen:
                        frames.extend(silent_chunks)
                        print("[*] 静音结束")
                        break
        self._save_wav(frames)
        print(f"[+] 已保存 {OUTPUT_FILE}")
        return OUTPUT_FILE

    def _save_wav(self, frames):
        with wave.open(OUTPUT_FILE, 'wb') as wf:
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(self.pa.get_sample_size(FORMAT))
            wf.setframerate(RATE)
            wf.writeframes(b''.join(frames))

    def close(self):
        self.stream.stop_stream()
        self.stream.close()
        self.pa.terminate()

# ====== 可打断播放 ======
def play_audio_interruptible(sound):
    if player_queue.full():
        player_queue.get_nowait()  # 丢弃旧任务
    data, fs = sf.read(sound, dtype='float32')
    sd.play(data, fs)
    while sd.get_stream().active:
        if interrupt_event.is_set():
            sd.stop()
            print("[!] 播放被打断")
            break
        sd.sleep(50)

def player_worker():
    while True:
        sound = player_queue.get()
        play_audio_interruptible(sound)
        player_queue.task_done()

# ====== 文件监听 ======
def monitor_flag(file_path):
    last_value = None
    global interrupt_event
    while True:
        try:
            with open(file_path, 'r') as f:
                line = f.readline().strip()
                if line == "True" and line != last_value:
                    print("[*] 唤醒信号触发")
                    interrupt_event.set()  # 中断当前流程
                    last_value = line
                    with open(file_path, 'w') as fw:
                        fw.write("False")
        except FileNotFoundError:
            pass
        time.sleep(0.2)

# ====== STT → RAG → TTS 流程 ======
def stt_rag_tts_pipeline(filepath):
    global conversation_id
    if interrupt_event.is_set():
        print("[*] 流程被中断，STT停止")
        return
    # STT
    text = stt_model.generate(input=filepath, data_type="sound", inference_clip_length=250, disable_update=True)[0]['text']
    print("[STT]", text)
    if interrupt_event.is_set():
        return

    # RAG
    API_URL = "http://192.168.166.144/v1/chat-messages"
    API_KEY = "app-MAzgaqOFk2jgM7wspctReZeG"
    headers = {"Content-Type": "application/json", "Accept": "text/event-stream",
               "Authorization": f"Bearer {API_KEY}"}
    payload = {"inputs": {}, "query": text, "response_mode": "streaming",
               "conversation_id": conversation_id, "user": "ShowRoom"}
    try:
        response = requests.post(API_URL, json=payload, headers=headers, stream=True)
        response.raise_for_status()
        stxt = ''
        for line in response.iter_lines():
            if interrupt_event.is_set():
                print("[!] RAG 被中断")
                return
            if not line:
                continue
            decoded = line.decode('utf-8')
            if decoded.startswith("data:"):
                data = json.loads(decoded[len("data:"):])
                if data.get("answer") not in ["<think>", "</think>"]:
                    stxt += data.get("answer","")
                    if stxt and stxt[-1] in ['，','。']:
                        print("[RAG]", stxt)
                        if not player_queue.full():
                            player_queue.put('outputs/gen_audio.wav')
                        stxt = ''
    except:
        pass

# ====== TTS 线程 ======
def tts_worker():
    while True:
        text = tts_queue.get()
        if interrupt_event.is_set():
            tts_queue.task_done()
            continue
        # 生成音频并放入播放队列
        print("[TTS]", text)
        if not player_queue.full():
            player_queue.put('outputs/gen_audio.wav')
        tts_queue.task_done()

# ====== 主循环 ======
if __name__ == "__main__":
    recorder = MicRecorder()
    threading.Thread(target=monitor_flag, args=(flag_path,), daemon=True).start()
    threading.Thread(target=player_worker, daemon=True).start()
    threading.Thread(target=tts_worker, daemon=True).start()

    while True:
        if interrupt_event.is_set():
            interrupt_event.clear()
            with process_lock:  # 保证单流程
                filepath = recorder.record_once()
                threading.Thread(target=stt_rag_tts_pipeline, args=(filepath,), daemon=True).start()
        time.sleep(0.1)
