import pyaudio
import webrtcvad
import wave
import threading
import time
import collections
import requests
import json
import os
from queue import Queue
import sounddevice as sd
import soundfile as sf
from funasr import AutoModel

# === 参数配置部分 ===
RATE = 16000
CHANNELS = 1
FORMAT = pyaudio.paInt16
CHUNK_MS = 30
CHUNK_SIZE = int(RATE * CHUNK_MS / 1000)
VAD_MODE = 2
SILENCE_TIMEOUT = 3.0
OUTPUT_FILE = "recorded.wav"

# 队列
tts_q = Queue()
player_q = Queue()

# 外部信号
recording_signal = False
flag_path = "/tmp/flag.txt"

# 🔴 全局打断事件
interrupt_event = threading.Event()
first_wakeup_done = False  # 判断第一次唤醒

# ============ 录音类 ============
class MicRecorder:
    def __init__(self):
        self.vad = webrtcvad.Vad(VAD_MODE)
        self.pa = pyaudio.PyAudio()
        self.stream = self.pa.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=RATE,
            input=True,
            frames_per_buffer=CHUNK_SIZE
        )

    def is_speech(self, frame_bytes):
        return self.vad.is_speech(frame_bytes, RATE)

    def record_once(self):
        print("[*] 等待录音信号...")
        while not recording_signal:
            if interrupt_event.is_set():
                return None
            time.sleep(0.1)

        print("[+] 录音开始")
        frames = []
        silent_chunks = collections.deque(maxlen=int(SILENCE_TIMEOUT * 1000 / CHUNK_MS))

        while True:
            if interrupt_event.is_set():
                print("[-] 录音被打断")
                return None
            frame = self.stream.read(CHUNK_SIZE, exception_on_overflow=False)
            if self.is_speech(frame):
                frames.append(frame)
                silent_chunks.clear()
            else:
                if frames:
                    silent_chunks.append(frame)
                    if len(silent_chunks) == silent_chunks.maxlen:
                        frames.extend(silent_chunks)
                        print("[-] 静音超时，录音结束")
                        break

        self._save_wav(frames)
        return OUTPUT_FILE

    def _save_wav(self, frames):
        with wave.open(OUTPUT_FILE, 'wb') as wf:
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(self.pa.get_sample_size(FORMAT))
            wf.setframerate(RATE)
            wf.writeframes(b''.join(frames))

    def close(self):
        self.stream.stop_stream()
        self.stream.close()
        self.pa.terminate()

# ============ 语音转文本 ============
def transcribe_with_funasr(filepath, stt_model):
    print("[*] 正在识别音频内容...")
    res = stt_model.generate(input=filepath, data_type="sound", inference_clip_length=250, disable_update=True)
    word_text = res[0]['text']
    print("[识别结果]:", word_text)
    return word_text

# ============ AI 响应（RAG API） ============
def AI_response(user_text, conversation_id):
    API_URL = "http://192.168.166.144/v1/chat-messages"
    API_KEY = "app-MAzgaqOFk2jgM7wspctReZeG"
    user = "ShowRoom"
    headers = {
        "Content-Type": "application/json",
        "Accept": "tex
