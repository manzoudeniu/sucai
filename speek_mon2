import pyaudio           # 用于音频采集
import webrtcvad         # 语音活动检测（VAD）
import wave              # 写入 WAV 音频文件
import threading         # 启动子线程
import time              # 时间控制
import collections       # 使用 deque 作为音频缓存
import openai            # 调用 OpenAI Whisper API 进行语音识别
import sys
import requests
import json
import os
from queue import Queue
from threading import Thread, Event
import sounddevice as sd
import soundfile as sf
from funasr import AutoModel

# === 参数配置部分 ===
RATE = 16000                     # 采样率为 16kHz，常用于语音识别
CHANNELS = 1                     # 单声道
FORMAT = pyaudio.paInt16         # 每帧 16 位整型数据
CHUNK_MS = 30                    # 每帧持续时间为 30 毫秒
CHUNK_SIZE = int(RATE * CHUNK_MS / 1000)  # 每块帧大小
VAD_MODE = 2                     # VAD 模式（0~3），越高越敏感
SILENCE_TIMEOUT = 3.0            # 静音超时阈值（秒）
OUTPUT_FILE = "recorded.wav"     # 临时保存录音的文件名

openai.api_key = "your_openai_api_key_here"  # 替换为你的 OpenAI API Key

player_q = Queue()
interrupt_event = Event()   # 打断播放事件
# ======================

# 外部录音触发信号
recording_signal = False

def set_recording_signal(value: bool):
    global recording_signal
    recording_signal = value

# === 录音器 ===
class MicRecorder:
    def __init__(self):
        self.vad = webrtcvad.Vad(VAD_MODE)
        self.pa = pyaudio.PyAudio()
        self.stream = self.pa.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=RATE,
            input=True,
            frames_per_buffer=CHUNK_SIZE
        )

    def is_speech(self, frame_bytes):
        return self.vad.is_speech(frame_bytes, RATE)

    def record_once(self):
        print("[*] 等待录音信号...")
        while not recording_signal:
            time.sleep(0.1)

        print("[+] 录音开始，检测语音...")
        frames = []
        silent_chunks = collections.deque(maxlen=int(SILENCE_TIMEOUT * 1000 / CHUNK_MS))

        while True:
            frame = self.stream.read(CHUNK_SIZE, exception_on_overflow=False)
            if self.is_speech(frame):
                frames.append(frame)
                silent_chunks.clear()
            else:
                if frames:
                    silent_chunks.append(frame)
                    if len(silent_chunks) == silent_chunks.maxlen:
                        frames.extend(silent_chunks)
                        print("[-] 静音超时，结束录音")
                        break

        self._save_wav(frames)
        print(f"[+] 已保存到 {OUTPUT_FILE}")
        return OUTPUT_FILE

    def _save_wav(self, frames):
        wf = wave.open(OUTPUT_FILE, 'wb')
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(self.pa.get_sample_size(FORMAT))
        wf.setframerate(RATE)
        wf.writeframes(b''.join(frames))
        wf.close()

    def close(self):
        self.stream.stop_stream()
        self.stream.close()
        self.pa.terminate()

# === STT ===
def transcribe_with_whisper(filepath, stt_model):
    print("[*] 正在识别音频内容...")
    res = stt_model.generate(input=filepath, data_type="sound", inference_clip_length=250, disable_update=True)
    word_text = res[0]['text']
    print(word_text)
    return word_text

# === AI RAG 请求 ===
def AI_response(user_text, conversation_id):
    API_URL = "http://192.168.166.144/v1/chat-messages"
    API_KEY = "app-MAzgaqOFk2jgM7wspctReZeG"
    user = "ShowRoom"
    headers = {
        "Content-Type": "application/json",
        "Accept": "text/event-stream",
        "Authorization": f"Bearer {API_KEY}"
    }

    payload = {
        "inputs": {},
        "query": user_text,
        "response_mode": "streaming",
        "conversation_id": conversation_id,
        "user": user
    }

    try:
        print("Request RAG:", time.ctime())
        response = requests.post(API_URL, json=payload, headers=headers, stream=True)
        response.raise_for_status()
        new_conv_id = None
        flag = 0
        stxt = ''
        for line in response.iter_lines():
            if not line:
                continue
            decoded = line.decode('utf-8')
            if decoded.startswith("data:"):
                data = json.loads(decoded[len("data:"):])
                if data.get("answer", "") == "<think>":
                    flag = 1
                if data.get("answer", "") == "</think>":
                    flag = 0
                    continue
                if flag == 0:
                    stxt += data.get("answer", "")
                if stxt:
                    if stxt[-1] in ['，', '。', '.', '!']:
                        print("AI:", stxt)
                        audio_path = test_tts(stxt)
                        player_q.put(audio_path)
                        stxt = ''

                if not new_conv_id:
                    new_conv_id = data.get("conversation_id", conversation_id)
        print("RAG response:", time.ctime())
        return new_conv_id

    except requests.exceptions.RequestException as e:
        print(f"\n[错误] 请求时发生异常: {e}")
        return None

# === TTS ===
def test_tts(tts_text):
    spk_id = "中文女"
    stream = True
    data = {
        "spk_id": spk_id,
        "tts_text": tts_text,
        "stream": stream,
        "speed": 1.1,
    }
    st = time.time()
    audio_file = f"outputs/gen_{int(st)}.wav"
    if stream:
        print("tts_text:", tts_text)
        response = requests.post("http://192.168.166.144:3005/cosyvoice", json=data, stream=True)
        print(f"Streaming TTS请求耗时：{time.time() - st}s")
        audio_content = b''
        for chunk in response.iter_content(chunk_size=1024):
            audio_content += chunk
    else:
        response = requests.post("http://192.168.166.144:3005/cosyvoice", json=data)
        print(f"请求耗时：{time.time() - st}s")
        audio_content = base64.b64decode(response.content)

    pcm2wav(audio_content, audio_file)
    return audio_file

def pcm2wav(pcm_data, out_file):
    with wave.open(out_file, "wb") as wav:
        wav.setnchannels(1)
        wav.setsampwidth(2)
        wav.setframerate(24000)
        wav.writeframes(pcm_data)

# === 播放器线程 ===
def player_worker():
    while True:
        audio_path = player_q.get()
        try:
            print(f"[播放] {audio_path}")
            data, fs = sf.read(audio_path, dtype='float32')

            block_size = fs // 10  # 每次播放0.1秒
            start = 0
            while start < len(data):
                if interrupt_event.is_set():
                    print("[播放] 被打断")
                    sd.stop()
                    break
                end = min(start + block_size, len(data))
                sd.play(data[start:end], fs)
                sd.wait()
                start = end

        except Exception as e:
            print(f"播放错误: {e}")
        finally:
            player_q.task_done()
            try:
                os.remove(audio_path)
            except:
                pass
            interrupt_event.clear()

# === 主程序 ===
if __name__ == "__main__":
    try:
        Thread(target=player_worker, daemon=True).start()
        stt_model = AutoModel(model="/home/b/daniel/funasr-project/FunASR/models", disable_update=True)
        file_path = "/tmp/flag.txt"
        recorder = MicRecorder()
        last_value = None

        while True:
            try:
                with open(file_path, 'r+') as f:
                    line = f.readline().strip()
                    if line == "True":
                        print("Detected True. Resetting flag.")
                        f.seek(0)
                        f.write("False")
                        f.truncate()

                        # ⚡ 打断正在播报
                        interrupt_event.set()

                        recording_signal = True
                        print("录音开始:", time.ctime())
                        filepath = recorder.record_once()
                        print("录音完成:", time.ctime())
                        recording_signal = False

                        print("识别音频内容:", time.ctime())
                        user_text = transcribe_with_whisper(filepath, stt_model)
                        print("识别音频完成:", time.ctime())

                        conversation_id = None
                        conversation_id = AI_response(user_text, conversation_id)

                    elif line != last_value:
                        print(f"Current content: {line}")
                    last_value = line
            except FileNotFoundError:
                print("File not found. Waiting for it to be created.")
            except Exception as e:
                print(f"Error reading file: {e}")

    except KeyboardInterrupt:
        pass
    finally:
        recorder.close()
